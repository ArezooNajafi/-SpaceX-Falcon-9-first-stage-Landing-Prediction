{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPpl6ax9yl24G5qo8WCwrC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArezooNajafi/-SpaceX-Falcon-9-first-stage-Landing-Prediction/blob/main/Falcon_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh6VNPTWOZtk"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "static_json_url='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/API_call_spacex_api.json'"
      ],
      "metadata": {
        "id": "FPickMEhefWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "response=requests.get(static_json_url)\n",
        "df=pd.json_normalize(response.json())\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "eOzetkJhegJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Vtpf4djXe4VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "hIigtdcGfEth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "rNWmf7uSiXK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "N2wpJEREi2j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "data = df[['rocket', 'payloads', 'launchpad', 'cores', 'flight_number', 'date_utc']]\n",
        "\n",
        "# We will remove rows with multiple cores because those are falcon rockets with 2 extra rocket boosters and rows that have multiple payloads in a single rocket.\n",
        "data = data[data['cores'].map(len)==1]\n",
        "data = data[data['payloads'].map(len)==1]\n",
        "\n",
        "# Since payloads and cores are lists of size 1 we will also extract the single value in the list and replace the feature.\n",
        "data['cores'] = data['cores'].map(lambda x : x[0])\n",
        "data['payloads'] = data['payloads'].map(lambda x : x[0])\n",
        "\n",
        "# We also want to convert the date_utc to a datetime datatype and then extracting the date leaving the time\n",
        "data['date'] = pd.to_datetime(data['date_utc']).dt.date\n",
        "\n",
        "# Using the date we will restrict the dates of the launches\n",
        "data = data[data['date'] <= datetime.date(2020, 11, 13)]"
      ],
      "metadata": {
        "id": "S_CLOEiAieoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBoosterVersion(data):\n",
        "    for x in data['rocket']:\n",
        "       if x:\n",
        "        response = requests.get(\"https://api.spacexdata.com/v4/rockets/\"+str(x)).json()\n",
        "        BoosterVersion.append(response['name'])"
      ],
      "metadata": {
        "id": "2Im4PzTOmgkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BoosterVersion = []\n",
        "PayloadMass = []\n",
        "Orbit = []\n",
        "LaunchSite = []\n",
        "Outcome = []\n",
        "Flights = []\n",
        "GridFins = []\n",
        "Reused = []\n",
        "Legs = []\n",
        "LandingPad = []\n",
        "Block = []\n",
        "ReusedCount = []\n",
        "Serial = []\n",
        "Longitude = []\n",
        "Latitude = []"
      ],
      "metadata": {
        "id": "_0hak2eamjuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BoosterVersion"
      ],
      "metadata": {
        "id": "fUQRgquimmdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call getBoosterVersion\n",
        "getBoosterVersion(data)"
      ],
      "metadata": {
        "id": "U5yL8bNUmrPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the dataset and uses the payloads column to call the API and append the data to the lists\n",
        "def getPayloadData(data):\n",
        "    for load in data['payloads']:\n",
        "       if load:\n",
        "        response = requests.get(\"https://api.spacexdata.com/v4/payloads/\"+load).json()\n",
        "        PayloadMass.append(response['mass_kg'])\n",
        "        Orbit.append(response['orbit'])"
      ],
      "metadata": {
        "id": "ljAbmhsYm5qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the dataset and uses the cores column to call the API and append the data to the lists\n",
        "def getCoreData(data):\n",
        "    for core in data['cores']:\n",
        "            if core['core'] != None:\n",
        "                response = requests.get(\"https://api.spacexdata.com/v4/cores/\"+core['core']).json()\n",
        "                Block.append(response['block'])\n",
        "                ReusedCount.append(response['reuse_count'])\n",
        "                Serial.append(response['serial'])\n",
        "            else:\n",
        "                Block.append(None)\n",
        "                ReusedCount.append(None)\n",
        "                Serial.append(None)\n",
        "            Outcome.append(str(core['landing_success'])+' '+str(core['landing_type']))\n",
        "            Flights.append(core['flight'])\n",
        "            GridFins.append(core['gridfins'])\n",
        "            Reused.append(core['reused'])\n",
        "            Legs.append(core['legs'])\n",
        "            LandingPad.append(core['landpad'])"
      ],
      "metadata": {
        "id": "NMcqPX9em8Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BoosterVersion[0:5]"
      ],
      "metadata": {
        "id": "enU3Id-7m89E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the dataset and uses the launchpad column to call the API and append the data to the list\n",
        "def getLaunchSite(data):\n",
        "    for x in data['launchpad']:\n",
        "       if x:\n",
        "         response = requests.get(\"https://api.spacexdata.com/v4/launchpads/\"+str(x)).json()\n",
        "         Longitude.append(response['longitude'])\n",
        "         Latitude.append(response['latitude'])\n",
        "         LaunchSite.append(response['name'])"
      ],
      "metadata": {
        "id": "7NwuJFDRnRv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call getLaunchSite\n",
        "getLaunchSite(data)"
      ],
      "metadata": {
        "id": "ZiZUvTDSncvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the dataset and uses the payloads column to call the API and append the data to the lists\n",
        "def getPayloadData(data):\n",
        "    for load in data['payloads']:\n",
        "       if load:\n",
        "        response = requests.get(\"https://api.spacexdata.com/v4/payloads/\"+load).json()\n",
        "        PayloadMass.append(response['mass_kg'])\n",
        "        Orbit.append(response['orbit'])"
      ],
      "metadata": {
        "id": "CdTHvVtxnrl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call getPayloadData\n",
        "getPayloadData(data)"
      ],
      "metadata": {
        "id": "ijjE8PNZndkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PayloadData[0:5]"
      ],
      "metadata": {
        "id": "kwe7ydsntJL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call getCoreData\n",
        "getCoreData(data)"
      ],
      "metadata": {
        "id": "GIdrJdNJnfxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "launch_dict = {'FlightNumber': list(data['flight_number']),\n",
        "'Date': list(data['date']),\n",
        "'BoosterVersion':BoosterVersion,\n",
        "'PayloadMass':PayloadMass,\n",
        "'Orbit':Orbit,\n",
        "'LaunchSite':LaunchSite,\n",
        "'Outcome':Outcome,\n",
        "'Flights':Flights,\n",
        "'GridFins':GridFins,\n",
        "'Reused':Reused,\n",
        "'Legs':Legs,\n",
        "'LandingPad':LandingPad,\n",
        "'Block':Block,\n",
        "'ReusedCount':ReusedCount,\n",
        "'Serial':Serial,\n",
        "'Longitude': Longitude,\n",
        "'Latitude': Latitude}"
      ],
      "metadata": {
        "id": "hHSwdvYXnqGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=pd.DataFrame(launch_dict)"
      ],
      "metadata": {
        "id": "PVmjcCfnpbuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in launch_dict.items():\n",
        "    print(f\"{key}: {len(value)}\")"
      ],
      "metadata": {
        "id": "DSt2G_Rwpwh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.nunique()"
      ],
      "metadata": {
        "id": "4wBmCTL5rbZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=ds[ds['BoosterVersion']!='Falcon 1']"
      ],
      "metadata": {
        "id": "HAkx8JHTrni7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.describe()"
      ],
      "metadata": {
        "id": "DUzhmzvysIJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.isnull().sum()"
      ],
      "metadata": {
        "id": "wpHgypyIuvV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of:\n",
        "# ds=ds['PayloadMass'].fillna(df['PayloadMass'].mean(), inplace=True)\n",
        "\n",
        "# Use this to fill NaN values in 'PayloadMass' column of ds DataFrame:\n",
        "mean=ds['PayloadMass'].mean()\n",
        "ds['PayloadMass'].fillna(mean, inplace=True)"
      ],
      "metadata": {
        "id": "cbdJZ9WFsNlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.head()"
      ],
      "metadata": {
        "id": "mGdhifXGuBEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.isnull().sum()"
      ],
      "metadata": {
        "id": "LB8PxuM21oGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.dtypes"
      ],
      "metadata": {
        "id": "PO6Cqp2X2QQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lunchstites_num = ds.groupby('LaunchSite')['LaunchSite'].value_counts()\n",
        "lunchstites_num"
      ],
      "metadata": {
        "id": "CXj87_Tt3SLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orbit_occur=ds['Orbit'].value_counts()\n",
        "orbit_occur"
      ],
      "metadata": {
        "id": "l01DrQ3y4ANs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landing_outcomes = ds['Outcome'].value_counts()\n",
        "landing_outcomes"
      ],
      "metadata": {
        "id": "wYyozTCjLfc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,outcome in enumerate(landing_outcomes.keys()):\n",
        "    print(i,outcome)"
      ],
      "metadata": {
        "id": "W9JiuYcJLs31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_outcomes=set(landing_outcomes.keys()[[1,3,5,6,7]])\n",
        "bad_outcomes"
      ],
      "metadata": {
        "id": "AifDZGQHL1_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of:\n",
        "# labeld_outcome= if outcome in bad_outcomes:\n",
        "#    landing_class=0\n",
        "# else:\n",
        "#    landing_class=1\n",
        "\n",
        "# Use this to create a new column 'landing_class' based on the 'Outcome' column:\n",
        "ds['landing_class'] = ds['Outcome'].apply(lambda outcome: 0 if outcome in bad_outcomes else 1)"
      ],
      "metadata": {
        "id": "lfWrBjRvU03O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.head(5)"
      ],
      "metadata": {
        "id": "WPCGv_yfVG7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[['landing_class']].head(8)"
      ],
      "metadata": {
        "id": "e8zYNkk7VQgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['landing_class'].mean()"
      ],
      "metadata": {
        "id": "0lRqtCPPWAU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['landing_class'].value_counts()"
      ],
      "metadata": {
        "id": "ILbNmcjZWMsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[ds['Orbit'].isin(['GEO', 'GTO'])].shape[0]"
      ],
      "metadata": {
        "id": "jcbhrDW2XWoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "pzDqvIJSiqHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\"\n",
        "response = requests.get(URL)\n",
        "response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "dataset_part_2_csv = io.BytesIO(response.content)  # Use response.content instead of response.text for binary data\n",
        "tbl = pd.read_csv(dataset_part_2_csv)\n",
        "tbl.head(5)"
      ],
      "metadata": {
        "id": "5EDcrPnRirZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(y=\"PayloadMass\", x=\"FlightNumber\", hue=\"Class\", data=tbl, aspect = 5)\n",
        "plt.xlabel(\"Flight Number\",fontsize=20)\n",
        "plt.ylabel(\"Pay load Mass (kg)\",fontsize=20)\n",
        "plt.show()\n",
        "#"
      ],
      "metadata": {
        "id": "pb9UoIr-jDYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(data=tbl,x='PayloadMass',y='LaunchSite',hue='Class',aspect=1)\n",
        "plt.xlabel(\"Pay load Mass (kg)\",fontsize=20)\n",
        "plt.ylabel(\"LaunchSite\",fontsize=20)\n",
        "plt.show()\n",
        "#"
      ],
      "metadata": {
        "id": "DSnkrDjvjtbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(data=tbl,x='PayloadMass',y='Orbit',hue='Class',aspect=1)\n",
        "plt.xlabel(\"Pay load Mass (kg)\",fontsize=20)\n",
        "plt.ylabel(\"Orbit\",fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tR8lwbgAmW6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to Extract years from the date\n",
        "year=[]\n",
        "def Extract_year():\n",
        "    for i in tbl[\"Date\"]:\n",
        "        year.append(i.split(\"-\")[0])\n",
        "    return year\n",
        "Extract_year()\n",
        "tbl['Date'] = year\n",
        "tbl.head()\n",
        ""
      ],
      "metadata": {
        "id": "hIbQqf-ImIz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "succes_rate=tbl[tbl['Class']==1]['LaunchSite'].value_counts()/tbl['LaunchSite'].value_counts()\n",
        "succes_rate"
      ],
      "metadata": {
        "id": "sanw0-Cvm6No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_sucess=tbl.groupby('Date')['Class'].mean()\n",
        "yearly_sucess"
      ],
      "metadata": {
        "id": "ThR2ge3GnfVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data=yearly_sucess)\n",
        "plt.xlabel(\"Year\",fontsize=20)\n",
        "plt.ylabel(\"Success Rate\",fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ekNITfu3ob-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = tbl[['FlightNumber', 'PayloadMass', 'Orbit', 'LaunchSite', 'Flights', 'GridFins', 'Reused', 'Legs', 'LandingPad', 'Block', 'ReusedCount', 'Serial']]\n",
        "features.head()"
      ],
      "metadata": {
        "id": "ghTjiBvtpN70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_cleaned=pd.get_dummies(features, columns=['Orbit', 'LaunchSite', 'LandingPad','Serial'])\n",
        "features_cleaned.head()"
      ],
      "metadata": {
        "id": "8c4eR8nrpXyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_cleaned=features_cleaned.astype('float64')\n",
        "features_cleaned.head()"
      ],
      "metadata": {
        "id": "sm4wEqRWp_ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import folium"
      ],
      "metadata": {
        "id": "ioxmUoSVp_yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import folium MarkerCluster plugin\n",
        "from folium.plugins import MarkerCluster\n",
        "# Import folium MousePosition plugin\n",
        "from folium.plugins import MousePosition\n",
        "# Import folium DivIcon plugin\n",
        "from folium.features import DivIcon"
      ],
      "metadata": {
        "id": "7eA2ch1ur_hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = folium.Map(location=[37.7749, -122.4194], zoom_start=6)\n",
        "\n",
        "# Create a MarkerCluster object\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "# Iterate through the DataFrame and add markers to the cluster\n",
        "for index, row in tbl.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        popup=row['LaunchSite']\n",
        "    ).add_to(marker_cluster)\n",
        "\n",
        "# Save the map to an HTML file\n",
        "m.save('launch_sites_map.html')\n",
        "m"
      ],
      "metadata": {
        "id": "llnsf8lwsCwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.11 -m pip install pandas dash"
      ],
      "metadata": {
        "id": "un5FlAwtwAJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  options=[{'label': 'All Sites', 'value': 'ALL'},{'label': 'site1', 'value': 'site1'}, ...]"
      ],
      "metadata": {
        "id": "UgBKbgflxCtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  dcc.Dropdown(id='id',\n",
        "                options=[\n",
        "                    {'label': 'All Sites', 'value': 'ALL'},\n",
        "                    {'label': 'site1', 'value': 'site1'},\n",
        "                ],\n",
        "                value='ALL',\n",
        "                placeholder=\"place holder here\",\n",
        "                searchable=True\n",
        "                ),"
      ],
      "metadata": {
        "id": "yO5kdbAoxESF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "3NxiiFBwwPx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = dash.Dash(__name__)\n",
        "\n",
        "# Define the layout of the application\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Interactive Dashboard for Launch Sites\"),\n",
        "\n",
        "    # Dropdown for selecting LaunchSite\n",
        "    dcc.Dropdown(\n",
        "        id='launchsite-dropdown',\n",
        "        options=[{'label': site, 'value': site} for site in tbl['LaunchSite']],\n",
        "        value='Site A',  # Default value\n",
        "        style={'width': '50%'}\n",
        "    ),\n",
        "\n",
        "    # Graph to display Price vs. Quantity based on LaunchSite selection\n",
        "    dcc.Graph(id='price-quantity-graph'),\n",
        "\n",
        "    # Optional: Adding a map to visualize launch site locations on the map\n",
        "    dcc.Graph(id='launchsite-map')\n",
        "])\n",
        "\n",
        "# Define the callback to update the graph\n",
        "@app.callback(\n",
        "    [Output('price-quantity-graph', 'figure'),\n",
        "     Output('launchsite-map', 'figure')],\n",
        "    [Input('launchsite-dropdown', 'value')]\n",
        ")\n",
        "def update_dashboard(selected_site):\n",
        "    # Filter the DataFrame based on the selected launch site\n",
        "    filtered_df = tbl[tbl['LaunchSite'] == selected_site]\n",
        "\n",
        "    # Create a bar chart showing Price vs. Quantity\n",
        "    price_quantity_fig = px.bar(filtered_df, x='LaunchSite', y=['Price', 'Quantity'],\n",
        "                                title=f'Price and Quantity of {selected_site}')\n",
        "\n",
        "    # Create a scatter mapbox to visualize the launch site on a map\n",
        "    map_fig = px.scatter_mapbox(filtered_df, lat='Latitude', lon='Longitude',\n",
        "                                hover_name='LaunchSite', size='Quantity',\n",
        "                                title=f'Launch Site Location: {selected_site}')\n",
        "\n",
        "    map_fig.update_layout(mapbox_style=\"carto-positron\", mapbox_zoom=5, mapbox_center={\"lat\": filtered_df['Latitude'].iloc[0], \"lon\": filtered_df['Longitude'].iloc[0]})\n",
        "\n",
        "    return price_quantity_fig, map_fig\n",
        "\n",
        "# Run the Dash app\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "zQyM47lRwmnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "\n",
        "# Create a list of unique launch sites\n",
        "launch_sites = [{'label': 'All Sites', 'value': 'ALL'}] + \\\n",
        "               [{'label': site, 'value': site} for site in tbl['LaunchSite'].unique()]\n",
        "\n",
        "# Create the Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "# Layout of the app\n",
        "app.layout = html.Div(children=[\n",
        "    html.H1('SpaceX Launch Records Dashboard',\n",
        "            style={'textAlign': 'center', 'color': '#503D36', 'font-size': 40}),\n",
        "\n",
        "    dcc.Dropdown(\n",
        "        id='site-dropdown',\n",
        "        options=launch_sites,\n",
        "        value='ALL',\n",
        "        placeholder=\"Select a Launch Site\",\n",
        "        searchable=True\n",
        "    ),\n",
        "\n",
        "    html.Br(),\n",
        "\n",
        "    html.Div(dcc.Graph(id='success-rate-chart')),\n",
        "\n",
        "    html.Br(),\n",
        "\n",
        "    html.Div(dcc.Graph(id='launchsite-map'))\n",
        "])\n",
        "\n",
        "# Callback to update charts based on selected site\n",
        "@app.callback(\n",
        "    [Output(component_id='success-rate-chart', component_property='figure'),\n",
        "     Output(component_id='launchsite-map', component_property='figure')],\n",
        "    [Input(component_id='site-dropdown', component_property='value')]\n",
        ")\n",
        "def update_dashboard(selected_site):\n",
        "    # Filter the dataframe based on the selected site\n",
        "    if selected_site == 'ALL':\n",
        "        filtered_tbl = tbl\n",
        "    else:\n",
        "        filtered_tbl = tbl[tbl['LaunchSite'] == selected_site]\n",
        "\n",
        "    # Compute success rate (Class column with capital 'C')\n",
        "    success_rate = filtered_tbl['Class'].mean()\n",
        "\n",
        "    # Success rate pie chart\n",
        "    success_fig = px.pie(\n",
        "        names=['Success', 'Failure'],\n",
        "        values=[success_rate, 1 - success_rate],\n",
        "        title=f\"Launch Success Rate for {selected_site}\"\n",
        "    )\n",
        "\n",
        "    # Map showing launch locations\n",
        "    map_fig = px.scatter_mapbox(\n",
        "        filtered_tbl,\n",
        "        lat=\"Latitude\",\n",
        "        lon=\"Longitude\",\n",
        "        hover_name=\"LaunchSite\",\n",
        "        hover_data=[\"PayloadMass\", \"Class\"],\n",
        "        color=\"Class\",\n",
        "        zoom=3,\n",
        "        height=500\n",
        "    )\n",
        "    map_fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "    map_fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
        "\n",
        "    return success_fig, map_fig\n",
        "\n",
        "# Run the app\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "ItVYK0RczI2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'Class' column into a NumPy array and assign it to variable Y\n",
        "Y = tbl['Class'].to_numpy()\n",
        "\n",
        "# Ensure that Y is a Pandas Series (in this case it is still a NumPy array but you can access it as a Pandas Series)\n",
        "print(type(Y))  # This will print <class 'numpy.ndarray'> because it's a NumPy array\n"
      ],
      "metadata": {
        "id": "ygyXEopu0NCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
        "import numpy as np\n",
        "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
        "import matplotlib.pyplot as plt\n",
        "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
        "import seaborn as sns\n",
        "# Preprocessing allows us to standarsize our data\n",
        "from sklearn import preprocessing\n",
        "# Allows us to split our data into training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Allows us to test parameters of classification algorithms and find the best one\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Logistic Regression classification algorithm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Support Vector Machine classification algorithm\n",
        "from sklearn.svm import SVC\n",
        "# Decision Tree classification algorithm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# K Nearest Neighbors classification algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "Sd6NxWYL0YeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# students get this\n",
        "transform = preprocessing.StandardScaler()"
      ],
      "metadata": {
        "id": "GADp3oJB0OyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=features_cleaned\n",
        "X=transform.fit_transform(X)\n",
        "Y=tbl['Class']"
      ],
      "metadata": {
        "id": "GrReX1Ft0l_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)"
      ],
      "metadata": {
        "id": "g7YhiUQU0hpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "KSsa_uXI0_7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters ={'C':[0.01,0.1,1],\n",
        "             'penalty':['l2'],\n",
        "             'solver':['lbfgs']}"
      ],
      "metadata": {
        "id": "Sy5N0TeI1WKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters ={\"C\":[0.01,0.1,1],'penalty':['l2'], 'solver':['lbfgs']}# l1 lasso l2 ridge\n",
        "lr=LogisticRegression()\n"
      ],
      "metadata": {
        "id": "CLIgePt01y7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# ... (other imports)\n",
        "\n",
        "# Define your parameters for GridSearchCV\n",
        "parameters = {\"C\": [0.01, 0.1, 1], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
        "\n",
        "# Create a LogisticRegression object\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Create a GridSearchCV object and fit it to your training data\n",
        "logreg_cv = GridSearchCV(lr, parameters, cv=10)  # Assuming you want 10-fold cross-validation\n",
        "logreg_cv.fit(X_train, Y_train)\n",
        "\n",
        "# Now you can access the best parameters and score\n",
        "print(\"tuned hpyerparameters :(best parameters) \", logreg_cv.best_params_)\n",
        "print(\"accuracy :\", logreg_cv.best_score_)"
      ],
      "metadata": {
        "id": "SgD1qxzD16KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y,y_predict):\n",
        "    \"this function plots the confusion matrix\"\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(y, y_predict)\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix');\n",
        "    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "h9yBZ-LaENtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat=logreg_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "FR7GcPUk2SzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC  # Import SVC\n",
        "\n",
        "# ... (other code) ...\n",
        "\n",
        "# Create the SVC object\n",
        "svm = SVC()\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n",
        "              'C': np.logspace(-3, 3, 5),\n",
        "              'gamma':np.logspace(-3, 3, 5)}\n",
        "\n",
        "# Create the GridSearchCV object and fit it\n",
        "svm_cv = GridSearchCV(svm, parameters, cv=10)  # Create svm_cv here\n",
        "svm_cv.fit(X_train, Y_train)  # Fit the model\n",
        "\n",
        "# Now you can print the results\n",
        "print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\n",
        "print(\"accuracy :\",svm_cv.best_score_)"
      ],
      "metadata": {
        "id": "_mGjDAT9Eizt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_kernel = svm_cv.best_params_['kernel']\n",
        "print(f\"The best kernel is: {best_kernel}\")\n"
      ],
      "metadata": {
        "id": "u2-p1U0ZKgIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat=svm_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "75Va4etpLDRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (previous code) ...\n",
        "\n",
        "# Create the GridSearchCV object and fit it\n",
        "svm_cv = GridSearchCV(svm, parameters, cv=10)\n",
        "svm_cv.fit(X_train, Y_train)\n",
        "\n",
        "# Calculate accuracy on the test data\n",
        "test_accuracy = svm_cv.score(X_test, Y_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Accuracy on test data: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "LOzymw4FLQCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'criterion': ['gini', 'entropy'],\n",
        "     'splitter': ['best', 'random'],\n",
        "     'max_depth': [2*n for n in range(1,10)],\n",
        "     'max_features': ['auto', 'sqrt'],\n",
        "     'min_samples_leaf': [1, 2, 4],\n",
        "     'min_samples_split': [2, 5, 10]}\n",
        "\n",
        "tree = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "5xw_kBK8LuUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_cv = GridSearchCV(tree, parameters, cv=10)\n",
        "tree_cv.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "AfE6qrQIL1YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = tree_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "rdmfli15MnTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = tree_cv.score(X_test, Y_test)\n",
        "print(f\"Accuracy on test data: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "wiqR2YUMMcgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "              'p': [1,2]}\n",
        "\n",
        "KNN = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "6j_4pgiLMWzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KNN= GridSearchCV(KNN, parameters, cv=10)\n",
        "KNN.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "nE1xdlOLM9ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = KNN.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "Ot0HzPVfND1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = KNN.score(X_test, Y_test)\n",
        "print(f\"Accuracy on test data: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "Nx435iKhNKHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-sql\n",
        "!pip install ipython-sql prettytable"
      ],
      "metadata": {
        "id": "w-RPJF4_c00w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext sql"
      ],
      "metadata": {
        "id": "9JaK-pLoc1rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv, sqlite3\n",
        "import prettytable\n",
        "prettytable.DEFAULT = 'DEFAULT'\n",
        "\n",
        "con = sqlite3.connect(\"my_data1.db\")\n",
        "cur = con.cursor()"
      ],
      "metadata": {
        "id": "Y1R1Og5Hc5Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%sql sqlite:///my_data1.db"
      ],
      "metadata": {
        "id": "iVgQm37Zd1S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\")\n",
        "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False,method=\"multi\")"
      ],
      "metadata": {
        "id": "5xMb8Pawc-BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DROP THE TABLE IF EXISTS\n",
        "\n",
        "%sql DROP TABLE IF EXISTS SPACEXTABLE;"
      ],
      "metadata": {
        "id": "dCpj7reIeL4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%sql create table SPACEXTABLE as select * from SPACEXTBL where Date is not null"
      ],
      "metadata": {
        "id": "NdnKVgrSdC5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install ipython-sql (only needed once)\n",
        "!pip install ipython-sql\n",
        "\n",
        "# Step 2: Load ipython-sql\n",
        "%load_ext sql\n",
        "\n",
        "# Step 3: Connect to your SQLite database (replace with your actual file path if needed)\n",
        "%sql sqlite:///spacex_data.db\n",
        "\n",
        "# Step 4: Run your SQL query\n",
        "x = %sql SELECT DISTINCT Launch_Site FROM SPACEXTABLE;\n",
        "print(x)\n"
      ],
      "metadata": {
        "id": "sEU9gGv-dIRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new table from cleaned data\n",
        "%%sql\n",
        "CREATE TABLE SPACEXTABLE AS\n",
        "SELECT * FROM SPACEXTBL\n",
        "WHERE Date IS NOT NULL;\n"
      ],
      "metadata": {
        "id": "765wdMQZecK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import libraries and connect to database\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import prettytable\n",
        "prettytable.DEFAULT = 'DEFAULT'\n",
        "\n",
        "# Connect to SQLite DB\n",
        "con = sqlite3.connect(\"my_data1.db\")\n",
        "cur = con.cursor()\n",
        "\n",
        "# Step 2: Load CSV and store in SQLite table\n",
        "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_dash.csv\")\n",
        "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False, method=\"multi\")\n",
        "\n",
        "# Step 3: Drop existing table if any, and create a clean version\n",
        "cur.execute(\"DROP TABLE IF EXISTS SPACEXTABLE;\")\n",
        "cur.execute(\"\"\"\n",
        "    CREATE TABLE SPACEXTABLE AS\n",
        "    SELECT * FROM SPACEXTBL;\n",
        "\"\"\")\n",
        "con.commit()\n",
        "# Step 1: Import libraries and connect to database\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import prettytable\n",
        "prettytable.DEFAULT = 'DEFAULT'\n",
        "\n",
        "# Connect to SQLite DB\n",
        "con = sqlite3.connect(\"my_data1.db\")\n",
        "cur = con.cursor()\n",
        "\n",
        "# Step 2: Load CSV and store in SQLite table\n",
        "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_dash.csv\")\n",
        "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False, method=\"multi\")\n",
        "\n",
        "# Step 3: Drop existing table if any, and create a clean version\n",
        "cur.execute(\"DROP TABLE IF EXISTS SPACEXTABLE;\")\n",
        "cur.execute(\"\"\"\n",
        "    CREATE TABLE SPACEXTABLE AS\n",
        "    SELECT * FROM SPACEXTBL;\n",
        "\"\"\")\n",
        "con.commit()\n",
        "\n",
        "# Step 4: Query distinct launch sites\n",
        "result = cur.execute(\"SELECT \\\"Launch Site\\\" FROM SPACEXTABLE;\") #added quotes\n",
        "rows = result.fetchall()\n",
        "\n",
        "# Step 5: Display results\n",
        "from prettytable import from_db_cursor\n",
        "result = cur.execute(\"SELECT DISTINCT \\\"Launch Site\\\" FROM SPACEXTABLE;\") #added quotes and DISTINCT\n",
        "table = from_db_cursor(result)\n",
        "print(table)\n",
        "# Step 1: Import libraries and connect to database\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import prettytable\n",
        "prettytable.DEFAULT = 'DEFAULT'\n",
        "\n",
        "# Connect to SQLite DB\n",
        "con = sqlite3.connect(\"my_data1.db\")\n",
        "cur = con.cursor()\n",
        "\n",
        "# Step 2: Load CSV and store in SQLite table\n",
        "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_dash.csv\")\n",
        "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False, method=\"multi\")\n",
        "\n",
        "# Step 3: Drop existing table if any, and create a clean version\n",
        "cur.execute(\"DROP TABLE IF EXISTS SPACEXTABLE;\")\n",
        "cur.execute(\"\"\"\n",
        "    CREATE TABLE SPACEXTABLE AS\n",
        "    SELECT * FROM SPACEXTBL;\n",
        "\"\"\")\n",
        "con.commit()\n",
        "# Step 1: Import libraries and connect to database\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import prettytable\n",
        "prettytable.DEFAULT = 'DEFAULT'\n",
        "\n",
        "# Connect to SQLite DB\n",
        "con = sqlite3.connect(\"my_data1.db\")\n",
        "cur = con.cursor()\n",
        "\n",
        "# Step 2: Load CSV and store in SQLite table\n",
        "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_dash.csv\")\n",
        "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False, method=\"multi\")\n",
        "\n",
        "# Step 3: Drop existing table if any, and create a clean version\n",
        "cur.execute(\"DROP TABLE IF EXISTS SPACEXTABLE;\")\n",
        "cur.execute(\"\"\"\n",
        "    CREATE TABLE SPACEXTABLE AS\n",
        "    SELECT * FROM SPACEXTBL;\n",
        "\"\"\")\n",
        "con.commit()\n",
        "\n",
        "# Step 4: Query distinct launch sites\n",
        "result = cur.execute(\"SELECT \\\"Launch Site\\\" FROM SPACEXTABLE;\") #added quotes\n",
        "rows = result.fetchall()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sS_ZkGHWeoPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Query distinct launch sites\n",
        "result = cur.execute(\"SELECT \\\"Launch Site\\\" FROM SPACEXTABLE WHERE \\\"Launch Site\\\" LIKE 'CCA%' LIMIT 5;\")\n",
        "rows = result.fetchall()\n",
        "\n",
        "# Print the result\n",
        "for row in rows:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "id": "lHYT46rNf2-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}